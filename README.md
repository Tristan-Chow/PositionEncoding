# PositionEncoding
In Google's 2017 paper Attention is all you need, the input of the encoder stacks combines word and position embedding, which captures more information regarding word sequence order, this project is based on that paper.


